---
title: "PracticalMachineLearning"
author: "Tammy Viggato"
date: "August 28, 2016"
output: html_document
---

## Project Introduction

Although many people use devices such as Jawbone Up, Nike FuelBand, and Fitbit to measure the how much of a particular activity they do, but not how well they do that activity.  The goal of this project is create a model that uses easily measurable parameters, and predict if an exercise was performed correctly.  I will use data collected by Groupware for the 'Weight Lifing Exercise Dataset' to perform this analysis.  

```{r setdirectory, include=FALSE}
#set working directory where data is saved
setwd("C:\\Users\\tammy\\Documents\\Coursera\\MachineLearning\\")
```

## Procedure

Before starting the analysis, we must conduct initial housekeeping, such as setting working directory, clearing old variables out of the workspace, loading libraries, and setting the seed.  After the housekeeping is finished, I load the data into R.  

```{r setup, warning=FALSE, message=FALSE}
#clean the current environment
rm(list=ls(all=TRUE)) 

#install required packages
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)

#set the seed
set.seed(5)

#load the data, setting no data values to NA
trainingset <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
testingset <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
```

I can now view the datasets to asses any data cleaning that may be required.  

```{r viewdata}
head(trainingset)
#head(testingset)
```

Inspection of this data shows there are many columns that contain only NA variables.  I remove these columns from the dataset, and am now ready to set the training data into a training set and a cross validation set.  It is necessary to break the training dataset into its own training and cross validation dataset so we can use the cross validation portion to check model output while still in the model development phase.

```{r clean}
#remove columns that don't have enough data to be included in the analysis
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]

#remove data that should not be included in the final model(ie, user and time of exercise)

trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]

#break the training data into a training and cross validation dataset
subtrain <- createDataPartition(y=trainingset$classe, p=0.7, list=FALSE)
intrain <- trainingset[subtrain, ] 
crossv <- trainingset[-subtrain, ]
```

## Create the initial models

I will test two model creation algorithms to determine which types gives the best output.  Both the generalized boosted model (gbm) and random forest (rf) algorithms are logical choices for this project, as they are both advanced algorithms used for classification models.  I will test the output of both algorithms against my cross validation dataset.  

#### Create the GBM model and test against the cross validation dataset
```{r gbmmodel, cache=TRUE, warning=FALSE, message=FALSE, echo=FALSE, results=FALSE}
#train the gbm model
gbmmodel <- train(classe ~ ., data=intrain, method="gbm")
```

```{r gbmpredict}
#predict witht the crossv
gbmpred <- predict(gbmmodel, crossv)
confusionMatrix(gbmpred, crossv$classe)
```

#### Create the RF model and test against the cross validation dataset
```{r rfmodel, cache=TRUE, warning=FALSE, message=FALSE, echo=FALSE}
#train the rf model
rfmodel <- randomForest(classe~.,data=intrain)
```

```{r rfpredict}
rfpred <- predict(rfmodel, crossv)
confusionMatrix(rfpred, crossv$classe)
```

Based on the results of this analysis, I will continue my work with model generated by the random forest algorithm.  


## Create Final Quiz Output to test algorithm
```{r rf_finaltesting}
rfpred_testing <- predict(rfmodel, testingset)
rfpred_testing
```

## Conclusion
The random forest algorithm created the better model for this dataset.  I used the results of the random forest model to generate the answers for the quiz portion of this assignment.  


